quantization_method: gptq
base_model: PLACEHOLDER
quantization_config:
  bits: 4
  batch_size: 16
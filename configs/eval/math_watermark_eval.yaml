name: "math_watermark_eval"
n_samples: 100
prompt_length: 100
min_token_length: 200
max_token_length: 200
dataset_config:
  path: "openai/gsm8k"
  name: "main"
  split: "test"
  data_fields: ["question", "answer"]
batch_size: 16
compute_ppl: true
ppl_model: "meta-llama/Llama-3.1-8B-Instruct"